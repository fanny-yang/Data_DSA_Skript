


\section{Wahrscheinlichkeitstheorie}


\vspace{15pt}


1933 ver\"offentlichte der russische Mathematiker Andrey Kolmogorov sein Buch \textit{Foundations of the Theory of Probability}, in dem er die drei Axiome der Wahrscheinlichkeitstheorie aufstellte. Es existiert ein Wahrscheinlichkeitsraum, der sich aus den drei Elementen $\Omega$, $\mathcal{F}$, $\mathbb{P}$ zusammensetzt.

\vspace{5pt}

\begin{enumerate}
	\item $\Omega$ ist eine Menge mit einer endlichen Anzahl an Elementen. $|\Omega|= n $
	\item $\mathcal{F}$ ist die Menge aller Ereignisse E, also Teilmengen von $\Omega$. Das hei"st f\"ur alle $E \in \mathcal{F}$  $E \subseteq \Omega$
	\item $\mathbb{P}$ bezeichnet die Wahrscheinlichkeitsverteilung. Diese weist jedem Ereignis in $\mathcal{F}$ eine reelle Zahl zu.  $\mathbb{P}: \mathcal{F} \longrightarrow \mathbb{R}$
	
	
\end{enumerate}

\vspace{10pt}



\begin{Def}[Kolmogorovs Axiome]

\vspace{5pt}

\begin{enumerate}
	\item Die Wahrscheinlichkeit eines Ereignisses ist eine positive, reelle Zahl, f\"ur die gilt \\ $\mathbb{P} (E) \geq 0$ f\"ur alle $E \in \mathcal{F}$.
	\item Die Menge aller Ergebnisse bezeichnet man als sicheres Ereignis, das die Wahrscheinlichkeit $\mathbb{P} (\Omega) = 1$ hat.
	\item Die Wahrscheinlichkeit der Vereinigung von disjunkten Ereignisssen ist gleich der Summe der Wahrscheinlichkeiten der disjunkten Ereignisse. 
	\vspace{3pt}
	\begin{equation*}
	\mathbb{P} (\cup_{i=1}^m E_{i}) = \sum_{i=1}^n \mathbb{P} (E_{i}) \quad \text{f\"ur alle} \: E_{1},...,E_{m} \in \mathcal{F}
	\end{equation*}
\end{enumerate}
\vspace{5pt}

$\mathbb{E}_{1},...,\mathbb{E}_{m}$ sind disjunkt, falls $\mathbb{E}_{i} \cap \mathbb{E}_{j} = \emptyset$ f\"ur alle $i,j= 1,2,...,m$. 
Hierbei bezeichnet $\emptyset$ ein unm\"ogliches Ereignis $\emptyset \in \mathcal{F}$.
\end{Def}

\vspace{5pt}

Die Wahrscheinlichkeit wird errechnet durch $ \mathbb{P}(E) = \frac {|E|}{|\Omega|}$.
Alternativ definieren wir $p_{i} = \mathbb{P} ({i})$\\ 
mit

$p_{i} \geq 0$  f\"ur $i \in \Omega$, f\"ur die gilt $\sum_{i\in \Omega} p_{i} =1$. 



\vspace{10pt}

\paragraph{Konsequenzen der Axiome:}

\vspace{5pt}

\begin{enumerate}
	\item $\mathbb{P} (\emptyset) = 0$
	\item Monotonie: Wenn immer $A\subseteq B$ dann: $\mathbb{P} (A) \leq \mathbb{P} (B)$
	\item $0 \leq \mathbb{P} (E) \leq 1$ \: f\"ur alle $E \in \mathcal{F}$
	\item $ \mathbb{P} (A \cup B) = \mathbb{P} (A) + \mathbb{P} (B) - \mathbb{P} (A \cap B)$ f\"ur alle $A,B \in \mathcal(F)$
\end{enumerate}


\vspace{10pt}

\paragraph {Zufallsvariablen}

\vspace{5pt}

In einem Wahrscheinlichkeitsraum $(\Omega, \mathcal{F}, \mathbb{P})$ k\"onnen wir eine Funktion $X:\Omega \longrightarrow \mathbb{R}^k$\: definieren, die dann einen k-dimensionalen Zufallsvektoren beschreibt. Im Fall von $k=1$ sprechen wir von einer Zufallsvariablen.

\vspace{10pt}

\paragraph {Erwartungswert}

\vspace{5pt}

 Der Erwartungswert einer Zufallsvariablen beschreibt die Zahl, die die Zufallsvariable im Mittel annimmt.
Sie wird definiert durch

\begin{equation*}
\mathbb{E} [X] = \sum_{x \in \Omega} X (i) * \mathbb{P} ({i}) = \sum_{x\in\mathcal{X}} X* \mathbb{P} (X=x) \text{,}
\end{equation*}
wobei $\mathcal{X}$ ein Wertebereich von x ist.

\vspace{10pt}

\paragraph {Varianz}

\vspace{5pt}

Die Varianz kennzeichnet die Ausdehnung einer Wahrscheinlichkeit. Die Varianz einer Zufallsvariable X ist definiert durch


\begin{equation*}
X= \mathbb{E} [X^2] - \mathbb{E} [X]^2 = \mathbb{E} [ (X - \mathbb{E} [X] )^2 ] 
\end{equation*}

\vspace{10pt}

\begin{Def}[Unabh\"angigkeit von Ereignissen]

\vspace{5pt}

\begin{enumerate}
	\item Wenn f\"ur Ereignisse $E, F \in \mathcal{F} $ gilt
	\begin{equation} \mathbb{P} (E\cap F)= \mathbb{P} (E)  \mathbb{P} (F) \end{equation},

dann sind E und F unabh\"angig. 

\item Zwei Zufallsvariablen 
\begin{equation*}
X_{1}: \Omega_{1} \longrightarrow \mathbb{R}, X_{2}: \Omega_{2} \longrightarrow \mathbb{R}
\end{equation*}
sind unabh\"angig, falls gilt, dass f\"ur alle $A, B \subseteq \mathbb{R}$
\begin{equation*}
\mathbb{P} (\{X_{1} \in A\} \cap \{X_{2} \in B\} ) = \mathbb{P} (\{X_{1} \in A\} * \mathbb{P} \{X_{2} \in B\} )
\end{equation*}
\end{enumerate}
\end{Def}
\vspace{10pt}

\paragraph {Marginale Wahrscheinlichkeiten}

Es seien $X_{1}, X_{2}$ Zufallsvariablen auf dem Wahrscheinlichkeitsraum $\Omega_{1}\times \Omega_{2}$, dann ist die marginale Wahrscheinlichkeit von $X_{1}$ definiert durch 

\begin{equation*}
\mathbb{P} (\{X_{1} \in A \} ) = \sum_{b \in \Omega_{2} } \mathbb{P} (\{X_{1} \in A\} \cap \{X_{2} \in b\})
\end{equation*}

\vspace{10pt}

\paragraph {Bedingte Wahrscheinlichkeit}
Die bedingte Wahrscheinlichkeit ist bestimmt durch 

\begin{equation*}
\mathbb{P} ({X_{1} \in A } | { X_{2} \in B } ) = \frac {\mathbb{P} ( {X_{1} \in A } \cap {X_{2} \in B })} {\mathbb{P} ({X_{2} \in B})}
\end{equation*}



\paragraph {Summe von Zufallsvariablen}

Gegeben seien zwei unabh√§ngige Zufallsvariablen
\begin{equation*}
X_{1}:\Omega \longrightarrow \mathbb{R}, X_{2}:\Omega \longrightarrow \mathbb{R}
\end{equation*}
Wir betrachten nun die Summe
\begin{equation*}
Y=X_{1}+X_{2}
.\end{equation*}

F\"ur die Berechnung der Verteilung der Summe 
\begin{equation*}
\{Y=l\}=\cup_{i=-\infty}^{\infty} \{X_{1}=1\} \cap \{X_{2}=l-i\}
\end{equation*}
beobachten wir zun\"achst, dass 
\begin{align*}
\mathbb{P} (/{Y=l/}) = \sum_{i=-\infty}^{\infty} \mathbb{P} (/{X_{1}=i/} \cap /{X_{2}=l-i/}) = \sum_{i=-\infty}^{\infty} \mathbb{P} (/{X_{1} = i/}) * \mathbb{P} (/{X_{2}=l-i/})
\end{align*}

\vspace{10pt}

\paragraph {Theorem: Linearit\"at des Erwartungswerts}

\vspace{5pt}

Angenommen, wir h\"atten eine Funktion
\vspace{3pt}

$f: \mathbb{R} \longrightarrow \mathbb{R}$ , f\"ur die gilt: 
\begin{equation*}
\int_{\mathbb{R}} f(x) dx = 1
\end{equation*}

\vspace{3pt}

dann k\"onnten wir eine Wahrscheinlichkeitsverteilung folgenderma"sen definieren:
\begin{equation*}
\mathbb{P} ({X\in A}) = \int_{X \in A} f(x) dx
\end{equation*}


