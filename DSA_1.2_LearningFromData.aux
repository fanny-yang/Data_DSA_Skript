\relax 
\global \df@index \z@ 
\catcode `"\active 
\select@language{ngerman}
\@writefile{toc}{\select@language{ngerman}}
\@writefile{lof}{\select@language{ngerman}}
\@writefile{lot}{\select@language{ngerman}}
\@writefile {toc}{\setcounter {tocdepth}{2}}
\newlabel{fig:titelbild}{{}{7}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Learning from Data}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Aus der Kursbeschreibung}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Vektoren}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Vektor- \& Unterraum}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Span}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Basis \& Dimension}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Lineare Unabh\"angigkeit}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Norm und Skalarprodukt}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Lineare Abbildungen}{9}}
\newlabel{Def:Def_1}{{3}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Matrix}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Matrix-Vektor-Multiplikation}{9}}
\df@numberfloat {1}{}{2.}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Matrix-Matrix-Multiplikation}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Analysis}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Wahrscheinlichkeitstheorie}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Optimierung}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Grundlagen der Optimierung}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Regression}{13}}
\df@numberfloat {2}{fig}{2.}
\newlabel{figure:Grafik-OptimierungLennart_LineareRegression.pdf}{{2.1}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Konvexit\IeC {\"a}t}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Konvexe Mengen}{14}}
\newlabel{figure:Grafik-OptimierungLukasL_KonvexeMengen}{{6.4}{14}}
\df@numberfloat {3}{fig}{2.}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Kugel}{14}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Quadrant}{14}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Eist\IeC {\"u}te}{14}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Box}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Konvexe Programme}{14}}
\@writefile{toc}{\contentsline {subparagraph}{\nonumberline Quadratische Programme}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Machine Learning}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Klassifikation und Regression}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Klassifikation}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Regression}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Support Vector Machines}{15}}
\df@numberfloat {4}{fig}{2.}
\newlabel{SVM1}{{2.3}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.1}Soft Margin SVMs}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Neuronale Netze}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Einf\IeC {\"u}hrung}{16}}
\df@numberfloat {5}{fig}{2.}
\newlabel{FigSVM}{{2.4}{17}}
\df@numberfloat {6}{fig}{2.}
\newlabel{FigNN}{{2.5}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Deep Learning}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Convolutional Neural Networks}{17}}
\bibdata{lit}
\bibstyle{plain}
\df@numberfloat {7}{fig}{2.}
\newlabel{FigConvNN}{{2.6}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}SVMs als Neuronale Netze}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5}Lineare Regression}{18}}
\ttl@finishall
